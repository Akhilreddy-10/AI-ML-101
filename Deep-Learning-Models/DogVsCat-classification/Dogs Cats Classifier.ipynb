{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog vs Cat Classification\n",
    "\n",
    "Two models are compared here. A normal CNN model and a fine tuned transfer learning model(VGG16 model). The dataset details are provided in the readme file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages (Tensorflow is the preferred library in this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f676715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba31a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f2f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUs available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num of GPUs available: \",len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a8923",
   "metadata": {},
   "source": [
    "# Organize into train, validation and test folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa833c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('dogsVcats_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sub folders to organize the raw images so that training becomes easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c952ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('train/dog') is False:\n",
    "    os.makedirs('train/dog')\n",
    "    os.makedirs('train/cat')\n",
    "    os.makedirs('test/dog')\n",
    "    os.makedirs('test/cat')\n",
    "    os.makedirs('valid/dog')\n",
    "    os.makedirs('valid/cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee436e",
   "metadata": {},
   "source": [
    "# Move randomly chosen images to directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db645379",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in random.sample(glob.glob('cat*'),500):\n",
    "    shutil.move(c,'train/cat')\n",
    "for c in random.sample(glob.glob('dog*'),500):\n",
    "    shutil.move(c,'train/dog')\n",
    "for c in random.sample(glob.glob('cat*'),100):\n",
    "    shutil.move(c,'test/cat')\n",
    "for c in random.sample(glob.glob('cat*'),200):\n",
    "    shutil.move(c,'valid/cat')\n",
    "for c in random.sample(glob.glob('dog*'),100):\n",
    "    shutil.move(c,'test/dog')\n",
    "for c in random.sample(glob.glob('dog*'),200):\n",
    "    shutil.move(c,'valid/dog')\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2f1fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dogsVcats_train/train'\n",
    "test_path = 'dogsVcats_train/test'\n",
    "valid_path = 'dogsVcats_train/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images from each folder and grouped into batches of size 10. (If OOM error occurs, reduce the batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cat', 'dog'],batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cat', 'dog'],batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cat', 'dog'],batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26b6d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "295f3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Regular CNN Model \n",
    "(Convolution and Max pool layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c2d7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0f62916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 401410    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "420316c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs refers to the number of times the models looks at the whole dataset\n",
    "\n",
    "Verbose controls the amount of information that will be displayed during training\n",
    "\n",
    "steps in each epoch = Total no. of training images/batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    epochs=2,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3b5b0",
   "metadata": {},
   "source": [
    "# Prediction of model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c448e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\n",
    "np.round(predictions)\n",
    "\n",
    "# 0 means cat and 1 means dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ead84528",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fda3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ae169c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'dog': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ffe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['cat','dog']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853219d2",
   "metadata": {},
   "source": [
    "# Model 2: VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83d4fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the layers in VGG16 are not trainable. An additional dense layer is added whose weights are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f77b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3658325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=2, activation='softmax'))\n",
    "# 2 units, 1 for rach class(cat or dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c14b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    epochs=2,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a7ad5",
   "metadata": {},
   "source": [
    "# Prediction of Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca3e33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80672170",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "cm_plot_labels = ['cat','dog']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter the hyper-parameters(no. of epochs, batch size) to get best results\n",
    "\n",
    "Calculate the accuracy and you will find the accuracy of VGG16 model to be high enough though it has fewer trainable parameters (Magic of transfer learning models)\n",
    "\n",
    "Write some code to compare accuracy, F1 score, Recall and precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
